---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  comment = "#>"
)
```

# canteral-cap-3

## Carregando o pacote
```{r}
library(tidyverse)
library(tidymodels)
library(gstat)
library(sp)
library(openxlsx)
library(readxl)
library(raster)
library(rstudioapi)
library(sp)
source("R/my-functions.R")
```

## Lendo a base de dados
```{r}
arco_desmatamento <- readr::read_rds("data/arco_desmatamento.rds")
```

## Conhecendo a base
```{r}
head(arco_desmatamento)
```

# Análise geoestatística

## grid refinado para a interpolação

```{r}
df_grid <- arco_desmatamento %>% 
  group_by(x,y) %>% 
  summarise(z = mean(xco2,na.rm = TRUE))

x<-df_grid$x
y<-df_grid$y
dis <- 20000 #Distância entre pontos
grid <- expand.grid(x=seq(min(x),max(x),dis), y=seq(min(y),max(y),dis))
sp::gridded(grid) = ~ x + y
```


## filtrar o banco de dados
```{r}
my_string <- "xco2"
my_year <- 2020
df <- my_df_generator(arco_desmatamento, my_year, my_string)
head(df)
```
## passando para o objeto
```{r}
sp::coordinates(df)=~ x+y  
form <- z ~ 1 
```

## Verificando o Variograma experimental

```{r}
cutoff_p <- 6e6
width_p <- 15
vari <- variogram(form, 
                  width = cutoff_p/width_p,
                  cutoff = cutoff_p ,
                  data=df)
vari %>%  
  ggplot(aes(x=dist, y=gamma)) +
  geom_point()
```
```{r}
m_vari <- fit.variogram(vari,
                        vgm(3.5,"Sph",30e5,3))
plot(vari,model=m_vari, col=1,pl=F,pch=16)


# jpeg(paste0("semivariogramas/",my_string,"-",my_year,".jpeg"),         # File name
#        width=8, height = 8, units=c("cm"), res = 300)
#     plot(vari, model=m_vari, col=1,pl=F,pch=16,
#          cex.axis=0.5,cex.lab = 0.5, cex=0.75,
#          main = "f) 2020 -"~Xco[2]~(ppm),
#          xlab="Distância de separação (m)", ylab="Semivariância")
#     
# 
# dev.off() 
```

## Krigagem
```{r}
ko_var <- krige(formula=form, df, grid, model=m_vari, 
    block=c(0,0),
    nsim=0,
    na.action=na.pass,
    debug.level=-1,  
    )
```

```{r}
as.tibble(ko_var)  %>%  
  ggplot(aes(x=x, y=y)) + 
  geom_tile(aes(fill = var1.pred)) +
  scale_fill_gradient(low = "yellow", high = "blue") + 
  coord_equal()
```

```{r}
contorno_arco <- read_rds("data/contorno_arco.rds")
pol_arco <- contorno_arco %>% as.matrix()
plot(as.tibble(grid) )
points(pol_arco[,1],pol_arco[,2],col="red")
```

```{r}
ko_var_df <- as.tibble(ko_var) %>% 
  mutate(flag = def_pol(x,y,pol_arco))
# como gravar ko_var_df de forma que tenhamos x, y e o nome da variável que está em "my_string)

obj_exp <- ko_var_df[1:3]
names(obj_exp) <- c("x","y",my_string)

# writexl::write_xlsx(obj_exp, paste0("mapas/",my_string,
#                                "-",my_year,".xlsx"))
```


```{r}
# jpeg(paste0("mapas/",my_string,"-",my_year,".jpeg"),         # File name
#        width=25, height = 15, units=c("cm"), res = 300)
# 
# ko_var_df %>%
#   filter(flag) %>%
#     ggplot(aes(x=x,y=y)) +
#     geom_tile(aes(fill = var1.pred)) +
#     scale_fill_viridis_c() +
#     coord_equal() +labs(x="",y="") +
#   theme(
#     plot.title = element_text(size = 20),
#     axis.text.x = element_text(size = 15),
#     axis.text.y = element_text(size = 15),
#     legend.text = element_text(size = 12),
#     legend.title = element_text(size = 15)) +
#   labs(fill=expression(Xco[2]), title = paste0("f) ", my_year)) +
#   map_theme()
# 
# #scale_fill_gradient(low = "#984EA3", high = "#FFD92F") - SIF
# #scale_fill_gradient(low = "yellow", high = "#543005")  - LST_Amp
# #scale_fill_gradient(low = "#FFD92F", high = "#238B45") - LAI
# dev.off()
```


## Manipulação do banco de dados

### Listando aquivos xlsx

```{r}
files <- list.files("mapas/", 
                    pattern = "xlsx",
                    full.names = TRUE)
```


```{r}
df_final <- purrr::map_df(files,my_xlsx_reader)
df_final$variable %>% unique()
df_final$year %>% unique()
```

## Calculando a Anomalia
```{r}
df_final <- df_final %>% 
  pivot_wider(names_from = variable, values_from = z) %>% 
  group_by(year) %>% 
  mutate(
    anomaly_xco2 = xco2 - median(xco2,na.rm = TRUE)
  ) %>% 
  mutate(flag = def_pol(x,y,pol_arco))
```


## Exportando a base de dados após krigagem e anomalia
```{r}
# write_rds(df_final, file = "data/base_krigagem.rds")
```


# Mapas de anomalia para xco2
```{r}
# Criar uma função para a paleta de cores invertida
paleta_invertida <- function(n) {
  cores <- rainbow(n = n)
  cores_invertidas <- rev(cores)  # Inverte a ordem das cores
  return(cores_invertidas)
}

# Usar a função para obter a paleta de cores invertida
cores_invertidas <- paleta_invertida(5)  # Substitua 10 pelo número desejado de cores

anos <- 2015:2020
letras <- letters[1:length(anos)]

for(i in 1:length(anos)){
  ano <- anos[i]
  letra <- letras[i]
  # jpeg(paste0("anomalias/xco2-",ano,".jpeg"),
  #      width=25, height = 12, units=c("cm"), res = 300)
  plot_anom <- df_final %>%
    filter(year == ano, flag) %>%
    ggplot(aes(x=x,y=y)) +
    geom_tile(aes(fill = anomaly_xco2)) +
    scale_fill_gradientn(colours = cores_invertidas) +
    coord_equal() +labs(x="",y="") +
    theme(
      plot.title = element_text(size = 20),
      axis.text.x = element_text(size = 15),
      axis.text.y = element_text(size = 15),
      legend.text = element_text(size = 12),
      legend.title = element_text(size = 15)) +
    labs(fill=expression(Anomalia~Xco[2]), title = paste0(letra,") ", ano)) +
    map_theme()
  print(plot_anom)
  dev.off()
}
```

## Aprendizado de Máquina

### Definindo o plano de multisession
```{r}
future::plan("multisession")
```

### Lendo a base

```{r}
data_set <- read_rds("data/base_krigagem.rds") %>% 
  mutate(year = as.numeric(year))
```


### Inspesionar a base quanto a valores faltantes
```{r}
visdat::vis_miss(data_set)
glimpse(data_set)
```

### Definindo a Base de treino e teste
```{r}
data_set_ml <- data_set
xco2_initial_split <- initial_split(data_set_ml, prop = 0.75)
xco2_train <- training(xco2_initial_split)
```


### Data prep

```{r}
xco2_recipe <- recipe(xco2 ~ ., 
                      data = xco2_train %>% 
                        ungroup() %>% 
                        filter(year == 2015) %>% 
                        dplyr::select(lai:xco2) %>% 
                        sample_n(7795*0.40)
                        
) %>%  
  step_normalize(all_numeric_predictors())  %>% 
  step_novel(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) #%>%
  #step_naomit(c(Ts, Us)) %>% 
  # step_impute_median(where(is.numeric)) %>% # inputação da mediana nos numéricos
  # step_poly(c(Us,Ts), degree = 2)  %>%  
  #step_dummy(all_nominal_predictors())
bake(prep(xco2_recipe), new_data = NULL)
```


```{r}
visdat::vis_miss(bake(prep(xco2_recipe), new_data = NULL))
```


### Definição da reamostragem
```{r}
xco2_resamples <- vfold_cv(xco2_train, v = 5)
```


### Definição do modelo

```{r}
xco2_rf_model <- rand_forest(
  min_n = tune(),
  mtry = tune(),
  trees = tune()
)   %>%  
  set_mode("regression")  %>% 
  set_engine("randomForest")
```

### Workflow

```{r}
xco2_rf_wf <- workflow()   %>%  
  add_model(xco2_rf_model) %>%  
  add_recipe(xco2_recipe)
```

### Tune

```{r}
grid_rf <- expand.grid(
  min_n = c(20,50,100),
  mtry = c(2,4),
  trees = c(50) #<-----------------------
)
```

```{r}
xco2_rf_tune_grid <- tune_grid(
 xco2_rf_wf,
  resamples = xco2_resamples,
  grid = grid_rf,
  metrics = metric_set(rmse)
)
autoplot(xco2_rf_tune_grid)
```

```{r}
collect_metrics(xco2_rf_tune_grid)
```

```{r}
xco2_rf_tune_grid %>%   show_best(metric = "rmse", n = 6)
```

```{r}
xco2_rf_best_params <- select_best(xco2_rf_tune_grid, "rmse")
xco2_rf_wf <- xco2_rf_wf %>% finalize_workflow(xco2_rf_best_params)
xco2_rf_last_fit <- last_fit(xco2_rf_wf, xco2_initial_split)
```

```{r}
xco2_test_preds <- bind_rows(
  collect_predictions(xco2_rf_last_fit)  %>%   mutate(modelo = "rf")
)

xco2_test <- testing(xco2_initial_split)
visdat::vis_miss(xco2_test)
```

```{r}
xco2_test_preds %>% 
  ggplot(aes(x=.pred, y=xco2)) +
  geom_point()+
  theme_bw() +
  geom_smooth(method = "lm") +
  ggpubr::stat_regline_equation(ggplot2::aes(
  label =  paste(..eq.label.., ..rr.label.., sep = "*plain(\",\")~~"))) +
  geom_abline (slope=1, linetype = "dashed", color="Red")
```
```{r}
xco2_rf_last_fit_model <-xco2_rf_last_fit$.workflow[[1]]$fit$fit
vip::vip(xco2_rf_last_fit_model,
    aesthetics = list(color = "black", fill = "orange")) +
    theme(axis.text.y=element_text(size=rel(1.5)),
          axis.text.x=element_text(size=rel(1.5)),
          axis.title.x=element_text(size=rel(1.5))
          )
```

```{r}
da <- xco2_test_preds %>% 
  filter(xco2 > 0, .pred>0 )

my_r <- cor(da$xco2,da$.pred)
my_r2 <- my_r*my_r
my_mse <- Metrics::mse(da$xco2,da$.pred)
my_rmse <- Metrics::rmse(da$xco2,
                         da$.pred)
my_mae <- Metrics::mae(da$xco2,da$.pred)
my_mape <- Metrics::mape(da$xco2,da$.pred)*100


vector_of_metrics <- c(r=my_r, R2=my_r2, MSE=my_mse, RMSE=my_rmse, MAE=my_mae, MAPE=my_mape)
print(data.frame(vector_of_metrics))
```

